
from langchain_ollama import ChatOllama

llm = ChatOllama(model="gemma2:2b", temperature=0.0)
print(f"ollama llm is running:{llm}")
